{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "YEq4x76AmpxJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deep Learning Frameworks"
      ],
      "metadata": {
        "id": "_f_cC4t-oidP"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6d0d0b66"
      },
      "source": [
        "### 1. What is TensorFlow 2.0, and how is it different from TensorFlow 1.x?\n",
        "\n",
        "TensorFlow 2.0 is a major revision of the open-source machine learning library TensorFlow. The key differences from TensorFlow 1.x include:\n",
        "\n",
        "*   **Eager execution by default:** TensorFlow 2.0 executes operations immediately, similar to how NumPy works. This makes debugging and development easier compared to TensorFlow 1.x's static graph execution.\n",
        "*   **Simplified API:** TensorFlow 2.0 streamlined and consolidated many APIs, making it more user-friendly. Keras is the recommended high-level API.\n",
        "*   **Removal of global collections:** TensorFlow 2.0 eliminated global collections, which improved clarity and reduced potential for errors.\n",
        "*   **Improved distribution strategy:** TensorFlow 2.0 provides easier ways to distribute training across multiple devices or machines.\n",
        "\n",
        "### 2. How do you install TensorFlow 2.0?\n",
        "\n",
        "You can install TensorFlow 2.0 using pip:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2a8aa116",
        "outputId": "860a1b4a-190a-4ebc-d28d-1ad69a92371a"
      },
      "source": [
        "pip install tensorflow[gpu]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: tensorflow[gpu] in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "\u001b[33mWARNING: tensorflow 2.18.0 does not provide the extra 'gpu'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow[gpu]) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow[gpu]) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow[gpu]) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow[gpu]) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow[gpu]) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow[gpu]) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow[gpu]) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow[gpu]) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow[gpu]) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow[gpu]) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow[gpu]) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow[gpu]) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow[gpu]) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow[gpu]) (4.14.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow[gpu]) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow[gpu]) (1.73.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow[gpu]) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow[gpu]) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow[gpu]) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow[gpu]) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow[gpu]) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow[gpu]) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow[gpu]) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow[gpu]) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow[gpu]) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow[gpu]) (0.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow[gpu]) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow[gpu]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow[gpu]) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow[gpu]) (2025.6.15)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow[gpu]) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow[gpu]) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow[gpu]) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow[gpu]) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow[gpu]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow[gpu]) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow[gpu]) (0.1.2)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ee51a279"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Sequential model\n",
        "model = keras.Sequential([\n",
        "    keras.Input(shape=(784,)), # Recommended way to specify input shape\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Functional API\n",
        "inputs = keras.Input(shape=(784,))\n",
        "x = layers.Dense(64, activation='relu')(inputs)\n",
        "outputs = layers.Dense(10, activation='softmax')(x)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 807
        },
        "id": "463ab78b",
        "outputId": "be779b52-a26c-4343-b30d-57f6def35a86"
      },
      "source": [
        "pip install torch torchvision torchaudio"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cudnn-cu12-9.1.0.70 nvidia-cusolver-cu12-11.6.1.9\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "nvidia"
                ]
              },
              "id": "5529216d39a64459ba54cba8671acd75"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3c404033",
        "outputId": "cca58f97-aec4-4b81-8813-e35ee00c7c70"
      },
      "source": [
        "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95032a9a"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(784, 128)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "028785a1"
      },
      "source": [
        "### 3. What is the primary function of the tf.function in TensorFlow 2.0?\n",
        "\n",
        "`tf.function` in TensorFlow 2.0 is used to convert Python code into a portable, high-performance TensorFlow graph. This allows for performance optimizations and deployment to various platforms (like mobile or web) that are not possible with eager execution alone. It essentially compiles your Python code into a static graph for efficiency.\n",
        "\n",
        "### 4. What is the purpose of the Model class in TensorFlow 2.0?\n",
        "\n",
        "The `Model` class in TensorFlow 2.0 is a central abstraction used to define and manage the architecture of a neural network. It allows you to group layers and handle training, evaluation, and prediction using its built-in methods like `compile()`, `fit()`, and `predict()`. It can be used to build both sequential models and more complex models with multiple inputs and outputs (using the Functional API).\n",
        "\n",
        "### 5. How do you create a neural network using TensorFlow 2.0?\n",
        "\n",
        "You can create a neural network in TensorFlow 2.0 using the Keras API, which is integrated into TensorFlow. Two common ways are:\n",
        "\n",
        "*   **Sequential API:** For simple feedforward networks, you can use `tf.keras.Sequential` to stack layers in a linear fashion.\n",
        "*   **Functional API:** For more complex models with multiple inputs, outputs, or shared layers, you can use the Functional API by defining input tensors and connecting layers like functions.\n",
        "\n",
        "(See the code cell above for examples of both.)\n",
        "\n",
        "### 6. What is the importance of Tensor Space in TensorFlow?\n",
        "\n",
        "In the context of TensorFlow, \"Tensor Space\" refers to the conceptual space where tensors reside and operations are performed. Tensors are the fundamental data structures in TensorFlow, representing multi-dimensional arrays. Operations in TensorFlow transform tensors from one space to another. While \"Tensor Space\" isn't a specific API or class, understanding how tensors flow through the computational graph is crucial for building and debugging models.\n",
        "\n",
        "### 7. How can TensorBoard be integrated with TensorFlow 2.0?\n",
        "\n",
        "TensorBoard can be integrated with TensorFlow 2.0 using the `tf.keras.callbacks.TensorBoard` callback during model training. This callback automatically logs information like training metrics, loss, and graphs, which can then be visualized in the TensorBoard web interface for monitoring and debugging.\n",
        "\n",
        "### 8. What is the purpose of TensorFlow Playground?\n",
        "\n",
        "TensorFlow Playground is an interactive web-based tool that allows users to experiment with small neural networks in their browser. It's a great resource for visualizing how different network architectures, activation functions, learning rates, and datasets affect the training process and model performance. It helps build intuition about neural networks without writing any code.\n",
        "\n",
        "### 9. What is Netron, and how is it useful for deep learning models?\n",
        "\n",
        "Netron is a free, open-source viewer for neural network, deep learning, and machine learning models. It supports a wide range of formats (including TensorFlow's saved models and Keras HDF5). Netron allows you to visualize the structure of your models, inspect the properties of layers, and understand the flow of data, which is very useful for debugging and understanding complex models.\n",
        "\n",
        "### 10. What is the difference between TensorFlow and PyTorch?\n",
        "\n",
        "Both TensorFlow and PyTorch are popular open-source deep learning frameworks. Key differences include:\n",
        "\n",
        "*   **Eager execution:** PyTorch has always had eager execution by default, while TensorFlow made it the default in 2.0. This makes PyTorch generally considered more Python-friendly and easier to debug.\n",
        "*   **Computational graphs:** TensorFlow uses a static graph by default (though 2.0 introduced `tf.function` for dynamic graphs), while PyTorch uses dynamic graphs. Dynamic graphs are more flexible for models with variable input sizes or control flow.\n",
        "*   **API:** TensorFlow's Keras API is often considered more high-level and user-friendly for beginners, while PyTorch's API is considered more flexible and Pythonic by some.\n",
        "*   **Community and adoption:** Both have large and active communities. TensorFlow has historically been more popular in industry, while PyTorch has gained significant traction in research.\n",
        "\n",
        "### 11. How do you install PyTorch?\n",
        "\n",
        "You can install PyTorch using pip, typically specifying your CUDA version for GPU support:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "862f708c",
        "outputId": "1d5ee27d-7754-465c-cabc-526378886931"
      },
      "source": [
        "pip install torch torchvision torchaudio"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e478e876"
      },
      "source": [
        "(See the code cells above for examples of installation commands.)\n",
        "\n",
        "### 12. What is the basic structure of a PyTorch neural network?\n",
        "\n",
        "A basic PyTorch neural network typically consists of:\n",
        "\n",
        "*   **`torch.nn.Module`:** The base class for all neural network modules. Your network should inherit from this class.\n",
        "*   **Layers:** Instances of classes from `torch.nn` that define the network's layers (e.g., `nn.Linear`, `nn.Conv2d`).\n",
        "*   **`__init__` method:** Defines the layers of the network.\n",
        "*   **`forward` method:** Defines how the input data flows through the layers to produce the output.\n",
        "\n",
        "(See the code cell above for an example of a basic PyTorch neural network structure.)\n",
        "\n",
        "### 13. What is the significance of tensors in PyTorch?\n",
        "\n",
        "Tensors are the fundamental data structure in PyTorch, similar to NumPy arrays but with the added ability to run on GPUs for accelerated computation. They are used to represent all data in a neural network, including input data, model parameters (weights and biases), and outputs.\n",
        "\n",
        "### 14. What is the difference between torch.Tensor and torch.cuda.Tensor in PyTorch?\n",
        "\n",
        "*   **`torch.Tensor`:** Represents a tensor on the CPU.\n",
        "*   **`torch.cuda.Tensor`:** Represents a tensor on the GPU.\n",
        "\n",
        "Operations performed on `torch.cuda.Tensor` are executed on the GPU, which is significantly faster for deep learning computations. You can move tensors between CPU and GPU using the `.to()` method or `.cuda()` and `.cpu()` methods.\n",
        "\n",
        "### 15. What is the purpose of the torch.optim module in PyTorch?\n",
        "\n",
        "The `torch.optim` module in PyTorch provides various optimization algorithms (like SGD, Adam, RMSprop) that are used to update the weights of a neural network during training. Optimizers calculate and apply gradients to minimize the loss function.\n",
        "\n",
        "### 16. What are some common activation functions used in neural networks?\n",
        "\n",
        "Common activation functions include:\n",
        "\n",
        "*   **ReLU (Rectified Linear Unit):** `f(x) = max(0, x)` - Simple and widely used, helps with vanishing gradients.\n",
        "*   **Sigmoid:** `f(x) = 1 / (1 + exp(-x))` - Squashes values between 0 and 1, often used in the output layer for binary classification.\n",
        "*   **Tanh (Hyperbolic Tangent):** `f(x) = (exp(x) - exp(-x)) / (exp(x) + exp(-x))` - Squashes values between -1 and 1, similar to sigmoid but zero-centered.\n",
        "*   **Softmax:** Used in the output layer for multi-class classification, converts a vector of numbers into a probability distribution.\n",
        "\n",
        "### 17. What is the difference between torch.nn.Module and torch.nn.Sequential in PyTorch?\n",
        "\n",
        "*   **`torch.nn.Module`:** The base class for defining any neural network module or layer. It's used when you need more control over the network's architecture and forward pass.\n",
        "*   **`torch.nn.Sequential`:** A container that allows you to stack layers in a sequential order. It's a convenient way to build simple feedforward networks where the output of one layer is the input to the next.\n",
        "\n",
        "`torch.nn.Sequential` is a specific type of `torch.nn.Module`.\n",
        "\n",
        "### 18. How can you monitor training progress in TensorFlow 2.0?\n",
        "\n",
        "You can monitor training progress in TensorFlow 2.0 using various methods, including:\n",
        "\n",
        "*   **TensorBoard:** As mentioned earlier, the `tf.keras.callbacks.TensorBoard` callback logs training metrics for visualization.\n",
        "*   **`model.fit()` output:** The `fit()` method displays progress bars and metrics during training.\n",
        "*   **Custom callbacks:** You can write custom callbacks to perform actions or log information at specific points during training.\n",
        "\n",
        "### 19. How does the Keras API fit into TensorFlow 2.0?\n",
        "\n",
        "Keras is the high-level API for building and training models in TensorFlow 2.0. It is the recommended way to build neural networks in TensorFlow due to its user-friendly and modular design. TensorFlow 2.0 integrates Keras directly as `tf.keras`.\n",
        "\n",
        "### 20. What is an example of a deep learning project that can be implemented using TensorFlow 2.0?\n",
        "\n",
        "A classic example is implementing an image classification model using a Convolutional Neural Network (CNN) on a dataset like MNIST or CIFAR-10. This involves loading the data, building a CNN model using `tf.keras.Sequential` or the Functional API, compiling the model, training it on the data, and evaluating its performance.\n",
        "\n",
        "### 21. What is the main advantage of using pre-trained models in TensorFlow and PyTorch?\n",
        "\n",
        "The main advantage of using pre-trained models is **transfer learning**. Pre-trained models have already learned to extract useful features from a large dataset (like ImageNet). By using a pre-trained model as a starting point and fine-tuning it on a new, smaller dataset, you can achieve good performance without needing a massive amount of data or computational resources for training from scratch. This significantly speeds up development and can lead to better results, especially on tasks with limited data."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#practical"
      ],
      "metadata": {
        "id": "knvqw7S7umDl"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3d6c617"
      },
      "source": [
        "### How do you install and verify that TensorFlow 2.0 was installed successfully?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05a91d6b",
        "outputId": "aba53d22-6376-46be-ac7f-211f44232189"
      },
      "source": [
        "# Install TensorFlow (if not already installed)\n",
        "!pip install tensorflow\n",
        "\n",
        "# Verify installation\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.14.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.73.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.6.15)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "2.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3040e380"
      },
      "source": [
        "### 1 How can you define a simple function in TensorFlow 2.0 to perform addition?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7460bfe2",
        "outputId": "5117ce20-2590-4916-bfc3-472c345dbf7c"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "@tf.function\n",
        "def add_two_numbers(x, y):\n",
        "  return x + y\n",
        "\n",
        "result = add_two_numbers(tf.constant(2), tf.constant(3))\n",
        "print(result)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(5, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceb66ade"
      },
      "source": [
        "### 2  How can you create a simple neural network in TensorFlow 2.0 with one hidden layer?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        },
        "id": "dadd9fce",
        "outputId": "1550c0b4-423d-481e-865b-729eb3a426ef"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(64, activation='relu', input_shape=(784,)),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m50,240\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">50,240</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m50,890\u001b[0m (198.79 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">50,890</span> (198.79 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m50,890\u001b[0m (198.79 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">50,890</span> (198.79 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. How can you create a simple neural network in TensorFlow 2.0 with one hidden layer2"
      ],
      "metadata": {
        "id": "bb2JskGTvKDA"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6c16e339"
      },
      "source": [
        "### 4 How can you visualize the training progress using TensorFlow and Matplotlib?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "id": "c2031629",
        "outputId": "63599374-c2dc-4feb-b07b-6c37ca2d7a73"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "\n",
        "# Generate some dummy data\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "x_train = x_train.reshape(-1, 784).astype(\"float32\") / 255.0\n",
        "x_test = x_test.reshape(-1, 784).astype(\"float32\") / 255.0\n",
        "\n",
        "# Create a simple model\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(64, activation='relu', input_shape=(784,)),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model and store the history\n",
        "history = model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test))\n",
        "\n",
        "# Plot training history\n",
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0.5, 1])\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8567 - loss: 0.4996 - val_accuracy: 0.9523 - val_loss: 0.1653\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9560 - loss: 0.1513 - val_accuracy: 0.9641 - val_loss: 0.1184\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9691 - loss: 0.1043 - val_accuracy: 0.9677 - val_loss: 0.1034\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9765 - loss: 0.0825 - val_accuracy: 0.9724 - val_loss: 0.0911\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9799 - loss: 0.0658 - val_accuracy: 0.9737 - val_loss: 0.0861\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAG2CAYAAACDLKdOAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAQd5JREFUeJzt3Xl4U2X+/vE7SZukLbQUSssquyzKvgkyglBlRPkKOgrIKOKgoqAg4ygogssILgPiCIo6LO7gBvIbFIUiOiIKAlWUgijKorQFga7QpMn5/VEIpBtNaZvm8H5d17maPOc5yefpoZ7bs1oMwzAEAABgEtZgFwAAAFCRCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUghpuPv/8cw0ePFgNGjSQxWLR8uXLz7jMunXr1KVLFzkcDrVs2VKLFy+u9DoBAEDoCGq4ycnJUceOHTVv3rwy9f/ll1905ZVX6tJLL1VycrImTpyoMWPG6OOPP67kSgEAQKiwVJcHZ1osFi1btkxDhgwpsc/999+vlStX6vvvv/e1DR8+XEePHtWqVauqoEoAAFDdhQW7gEBs2LBBiYmJfm0DBw7UxIkTS1wmLy9PeXl5vvder1eHDx9WnTp1ZLFYKqtUAABQgQzDUFZWlho0aCCrtfQDTyEVblJTU5WQkODXlpCQoMzMTB07dkwRERFFlpk5c6YeeeSRqioRAABUon379qlRo0al9gmpcFMeU6ZM0aRJk3zvMzIydN5552nfvn2Kjo4OYmUAAKCsMjMz1bhxY9WsWfOMfUMq3NSrV09paWl+bWlpaYqOji52r40kORwOORyOIu3R0dGEGwAAQkxZTikJqfvc9OrVS0lJSX5tq1evVq9evYJUEQAAqG6CGm6ys7OVnJys5ORkSQWXeicnJ2vv3r2SCg4p3XTTTb7+Y8eO1e7du3Xfffdpx44dev755/X222/rnnvuCUb5AACgGgpquPnmm2/UuXNnde7cWZI0adIkde7cWdOmTZMkHThwwBd0JKlZs2ZauXKlVq9erY4dO2rWrFn6z3/+o4EDBwalfgAAUP1Um/vcVJXMzEzFxMQoIyODc24AAAgRgWy/Q+qcGwAAgDMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMJqWdLAQCAogzDkMdrKN9ryO3xKt9jyO0t+Hn6a7fHq3yvoXyPV26PofxC7SeXzfeemO9rP7GM9/S2on1Pzm9et4bu/3OboP0+CDcAgHOSYRi+Dbz/hrzwRvv0oHBqA15cODi9/eSyJX2+7zNLnF/Q5vGe/vklB5HqpPN5eUH9fsINAKDS5Xu8ynF5dMzlUY4rv+BnXr5y3R7l5nmU68pXrsujXJdHx92e00JD0Y1/aXseirQX+pzT+3q81SsQVDSLRQq3WhVmsyjMalG47eRrq8JtFoXZrH7tvr42q8KtlkKvTyxzok/4iWWLzi94HV/TEdSxE24AAJIK9mS4PN4TAcSjY6585eR5ToSO/EI/C17n5BUKLKfPPy28uDzeYA+vTGzWkoLAaRv/EsLB6e2nh4Mwq//nlD1c+LcXFy5KCyw2qyXYv86gIdwAQIgxDEN5+d6CPR+uwuHj1OucvHz/oHJ6vzyPct35J/aanAon+ZW8N8NmtSjSblOUPUyRdpsiHTZFhocp0lHQFmG3yRFm9d8z4LdRDyRcnDkc+H2+1SJrVQQCwzgxeSTD6z95T7YZp7W7ivYzjIK++V7JfXp7Mct7i/megL6/uH6FP69Q35oNpM4jK/93WQLCDQBUEq/X0DF38Xs+cvI8Oub23/Phm18ocJweTo6d6FPZR1TsNuuJ4GFTpONEELHbFGn3fx3lKNQWblENm0c1bB5FWvMVZXMrwpqvSItbDotb4YZLlnyX5MmV8vOk/OMnprxTPz3uQhtSQ/J4JFdxG2Kj+I2r30a8pA18MZNfP6OEzyxtA1+GcCFzHw6TJDXuSbgBgGDyeA2/PR85efk65i5hz8eJvSWFA8fph2WO+cKLp9Jrd4ZbT4WLcKui7VJMuEfR4V5Fh3kUHZ6vKKtXNcPyFWXzKNKWr0hrviIs+YqwuuWUW06LWw65ZZdb4SoIIDZPXtHQkX9c8rik7GLaT/705lf6mM8pFmsJk63gpJrC7VbbideWQn0LL285rW8gn3v6Zxe3vFWyWqXYZkH9tRFuAIQkr9dQ1vF8Hcl16UiuS0ePuXU016WMXHcxgeO080fcpwLKyUCTl18x54NY5ZVdBUGhptyKs7hkV76ccis63HMibHhU0+ZRjbB81bB5FGXLV6TNowiLW5HWfDktbkWcFjYcpwWOMK9LNq9LNm+ebN48WTx5spwMFW6XdOy4qtVeAWuYFOaUwhySzVHw8+T7Yn/aC35aw09sTAtvZAtvTC3FbHjPMBW7kS5hQ20tLVgUWr7YGiwlfG5xAaSk8Z27582cDcINgKDLy/foaK67IKjkFISUIyfen3zt3+ZWxjG339UuFnkVLo/scsuufDnklsPiKvh5crK4FSfXieCQL4fFLYdcctgK5jstbtWw5Z/Yu+E5sYfDLacl/8TeDdeJz3fLbrgUZrgVZuQVBA6PS1bDXfpAvZKq8gpZWxnDRGmhwy+UlNS3mD42h2RjE4Pg4F8egNJ5PQWHIjyugnMhPK5T50UUavfmu3Ts2DHlHDumnGO5OnbsuI4fP6bjx48rL69gcrvy5HYdV77LJW9+njz5Llk8LtktHoUr3zc1VL6aKV/hloL39tPmhVvyFR5+ss0juyVfYarAQ0DeE9PZsFilsIhyBAqnZCtD6DjTXhCbnf/rxzmLcAMEg2EUGw78X59pfkmviw8egX2GW8aJNotR9q28VVLUianMLKqc/xLZStqzUEoYOFPoOFMwOX0vB3stgKDhrw/nLq9HOp4h5f5xajp25MRJkxUZNgq15edJ3jMcvqgGSvp/fpdhk1thvsmlMLmN09/b5LGES7ZwyWaXxWaXwhyyhdtlC3MozO5QuN2hcLtTdodDTodTTmeE7A6nrGF233IFU1lfO057feK9lUfnAecqwg3MweuVjh+Vcg9Lxw77BxbfdKRokKlOJ1/6baALb8TDpTCHvNZwX4jIM2zKM8KU57XpmNemYx6rcjxW5eZblX1iynJblOm2yOULH7bTXp8KJy6jUFg5EVg81nBFOp2KjIxQzchI1YiMVGyUXbFRdtWKDFdspF21IsJVK9Ku2Khw1YksaHeE2YL92wRwDiPcoPoxjNP2qJwIKkUCy+Gi8wM4fOLHESNF1pYi60gRsVK4sxx7DuyFptL7eq3hynJbdCRPOpwnHT3m0ZHcfN/Jsqf/PJLrVkZmwc+zubQ4ym7zhZDYSLtqRdpVP7IgmNSKCFds1ImQEmlX7In2mo6wqrmpGQBUIMINKpdhSHmZJ0JIMXtUjhUKKSdfG+XciNtrngoqflNs0baI2gV9beFnNcTjbk+xV/lkHHPrSM7JK32O6Uhuhi+wZBxzl/smbDarxRc+Yv3Cyam9KafmF7yOYW8KgHMI4QZlZxiSK7vkwzynH+45/X15b+plr3HaHpXCgaV20RATUbvghM+zkHncrT+yXacuQc5xl7g35eiJ+6scd5f/spoajrBTh3cKBZbY09pjTwSVWlHhqukIk4WrYACgRISbc5VhSO7cYg71FHe+ymnnsXhc5fu+8MjTQkkxe08KB5eI2gWHhyqZ12vo+98ztCYlXUkpafrh98xyfU6Y1VJKOCnUdmIPS60Iu+xhnPQKABWNcGMWrtzSD/MU99pTzruJhTmlyLji956cPG+lcFgJj6jY8Z6F426P1v90SGtS0rV2R5rSMv1/D4X3psQWG07896zUYG8KAFQbhJvqyH28mPNSznBCbf6x8n2XzVHoUE8xe1cKHxqyR1bseKtAetZxrU1J15qUdH3x00G/Q0mRdpsuaVVXA9rG69I28Yqr4QhipQCAs0W4qWz5eSWcSFvc+Son2tw55fsum72UvSclnKcSHmnKu5gahqGUA1lKSknTmpQ0fbs/w29+gxinBrRNUGK7BF3UvDYn2wKAiRBuKkr6DumL2UX3rriyy/d51rDiz0Mp7Sogew1TBpWyysv36Kvdh7Vme5rW7kjXb0f992Z1bBSjxLYJGtA2QW3r1+QwEgCYFOGmoriype+WFj/PYjvzVT6FDwE5ap7TQaWs/sjO09od6UpKSdf/dh1UjuvUJeTOcKv6tKyrxLbx6t8mXvHRlX+CMgAg+Ag3FSW2mXT5P4u/CsgZQ1CpIIZhaFd6ttakpCkpJV1b9h6Rcdr9YuJrOgoON7WN18Ut4+QM53ATAJxrCDcVJaqO1PuuYFdhSm6PVxt/OewLNHsP5/rNv6BBtC/QXNgghjvqAsA5jnCDaulorkvrdh7UmpQ0fbbzoLLyTt0I0B5mVe8WdTSgbYIGtIlXg1rV5zJzAEDwEW5Qbew+mK2klHStTknT5j1H5Dnt+QRxNey6tHW8EtslqE/LOEU5+KcLACgeWwgETb7Hq817jvgON+0+5H8JfOuEmkpsF68BbRPUqVEtDjcBAMqEcIMqlXncrc92HlRSSpo+3XlQGcfcvnnhNosual5HA9oUBJrGtUPvZoEAgOAj3KDS7f0jt2DvzI40fb37sPJPO9xUKzJc/VsXhJlLzo9TTefZPaEbAADCDSqcx2soed8R38Mof0zzv5Fhi7pRvpvpdTmvlsJsPDwSAFBxCDeoEDl5+frfroNavT1d63am64+cU08Pt1kt6t401hdomsVFBbFSAIDZEW5Qbr8dPXbi2U3p+urnP+TynHoYZU1nmPq1jldi23j1Oz9eMZEcbgIAVA3CDcrM6zW07bcMrTkRaFIOZPrNb1InUgPaJCixXby6N62tcA43AQCCgHCDUh1zefTFT4eUlJKmpB3pOpiV55tntUhdm8T67g7com4NHkYJAAg6wg2KSMs8rqQTJwN/8dMh5eWfOtxUwxGmS86P04A2Cbq0TbxqR9mDWCkAAEURbiDDMPTD75lKSknXmpQ0bfstw29+w1oRSmxbcLl2z+a15QjjYZQAgOqLcHOOOu72aMPuP7Rme5rW7kjXgYzjvnkWi9SxUS0lti143EHrhJocbgIAhAzCzTnkUHae1u5I15rtBYebcl0e37yIcJv6tIpTYtt4XdomXvE1nUGsFACA8iPcmJhhGNqZluU73JS876iMUzcHVr1opwa0jVdi2wT1alFHznAONwEAQh/hxmRc+V59/csfvkCz/8gxv/kXNoxWYtsEJbZN0AUNojncBAAwHcKNCRzJcenTnelKSknXZz8eVHZevm+eI8yqi1vGaUDbeA1ok6B6MRxuAgCYG+EmBBmGoZ8P5py4O3CaNu85otOeRam4Go4TT9aOV59WcYq0s5oBAOcOtnohwu3x6ptfjxQ8XTslTb/+kes3v029miee3RSvjo1qyWrlcBMA4NxEuKnGMo65te7E4aZ1O9OVefzU4aZwm0UXNa/jCzSNYiODWCkAANUH4aaa+fVQzom9M+na9Oth5Z92vCk2Mlz92xQ86uBP59dVDQerDwCAwtg6BpnHa2jL3iO+QPNTerbf/JbxNU5c3RSvzufFysbhJgAASkW4CYKs4279b9chrUlJ06c70nUk1+2bF2a1qEez2r6HUTapExXESgEACD2Emyqy/0iu794zX+3+Q27PqcNN0c4wXdqm4NlNfc+vq5iI8CBWCgBAaCPcVBKv19C3+4/6DjftSM3ym98sLurE5doJ6tY0VuE2a5AqBQDAXAg3FSjXla//7TqkpJQ0rd1xUIey83zzrBapW5PaSmxXEGha1K0RxEoBADAvwk0FWbM9TXe+uUWufK+vrYYjTH3Pr6vEdvHqd368YqPsQawQAIBzA+GmgrRtEC1XvleNa0doQJuCZzf1aFZb9jAONwEAUJUINxWkYa0Irf17XzWLi+JhlAAABBHhpgI15zwaAACCjmMmAADAVAg3AADAVIIebubNm6emTZvK6XSqZ8+e2rhxY4l93W63Hn30UbVo0UJOp1MdO3bUqlWrqrBaAABQ3QU13CxdulSTJk3S9OnTtWXLFnXs2FEDBw5Uenp6sf2nTp2qF198Uc8995y2b9+usWPHaujQodq6dWsVVw4AAKori2EYxpm7VY6ePXuqe/fumjt3riTJ6/WqcePGuuuuuzR58uQi/Rs0aKAHH3xQ48aN87Vde+21ioiI0Ouvv16m78zMzFRMTIwyMjIUHR1dMQMBAACVKpDtd9D23LhcLm3evFmJiYmnirFalZiYqA0bNhS7TF5enpxOp19bRESEvvjiixK/Jy8vT5mZmX4TAAAwr6CFm0OHDsnj8SghIcGvPSEhQampqcUuM3DgQM2ePVu7du2S1+vV6tWr9f777+vAgQMlfs/MmTMVExPjmxo3blyh4wAAANVL0E8oDsSzzz6rVq1aqU2bNrLb7Ro/frxGjx4tq7XkYUyZMkUZGRm+ad++fVVYMQAAqGpBCzdxcXGy2WxKS0vza09LS1O9evWKXaZu3bpavny5cnJytGfPHu3YsUM1atRQ8+bNS/weh8Oh6OhovwkAAJhX0MKN3W5X165dlZSU5Gvzer1KSkpSr169Sl3W6XSqYcOGys/P13vvvaerr766sssFAAAhIqiPX5g0aZJGjRqlbt26qUePHpozZ45ycnI0evRoSdJNN92khg0baubMmZKkr7/+Wr/99ps6deqk3377TQ8//LC8Xq/uu+++YA4DAABUI0ENN8OGDdPBgwc1bdo0paamqlOnTlq1apXvJOO9e/f6nU9z/PhxTZ06Vbt371aNGjU0aNAgvfbaa6pVq1aQRgAAAKqboN7nJhi4zw0AAKEnJO5zAwAAUBkINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFSCHm7mzZunpk2byul0qmfPntq4cWOp/efMmaPWrVsrIiJCjRs31j333KPjx49XUbUAAKC6C2q4Wbp0qSZNmqTp06dry5Yt6tixowYOHKj09PRi+7/55puaPHmypk+frpSUFC1YsEBLly7VAw88UMWVAwCA6iqo4Wb27Nm69dZbNXr0aLVr107z589XZGSkFi5cWGz/L7/8UhdffLFuuOEGNW3aVJdffrlGjBhxxr09AADg3BG0cONyubR582YlJiaeKsZqVWJiojZs2FDsMr1799bmzZt9YWb37t368MMPNWjQoBK/Jy8vT5mZmX4TAAAwr7BgffGhQ4fk8XiUkJDg156QkKAdO3YUu8wNN9ygQ4cOqU+fPjIMQ/n5+Ro7dmyph6VmzpypRx55pEJrBwAA1VfQTygOxLp16zRjxgw9//zz2rJli95//32tXLlSjz32WInLTJkyRRkZGb5p3759VVgxAACoakHbcxMXFyebzaa0tDS/9rS0NNWrV6/YZR566CHdeOONGjNmjCSpffv2ysnJ0W233aYHH3xQVmvRrOZwOORwOCp+AAAAoFoK2p4bu92url27Kikpydfm9XqVlJSkXr16FbtMbm5ukQBjs9kkSYZhVF6xAAAgZARtz40kTZo0SaNGjVK3bt3Uo0cPzZkzRzk5ORo9erQk6aabblLDhg01c+ZMSdLgwYM1e/Zsde7cWT179tRPP/2khx56SIMHD/aFHAAAcG4LargZNmyYDh48qGnTpik1NVWdOnXSqlWrfCcZ7927129PzdSpU2WxWDR16lT99ttvqlu3rgYPHqzHH388WEMAAADVjMU4x47nZGZmKiYmRhkZGYqOjg52OQAAoAwC2X6H1NVSAAAAZxJwuGnatKkeffRR7d27tzLqAQAAOCsBh5uJEyfq/fffV/PmzXXZZZdpyZIlysvLq4zaAAAAAlaucJOcnKyNGzeqbdu2uuuuu1S/fn2NHz9eW7ZsqYwaAQAAyuysTyh2u916/vnndf/998vtdqt9+/a6++67NXr0aFksloqqs8JwQjEAAKEnkO13uS8Fd7vdWrZsmRYtWqTVq1froosu0t/+9jft379fDzzwgNasWaM333yzvB8PAABQLgGHmy1btmjRokV66623ZLVaddNNN+mZZ55RmzZtfH2GDh2q7t27V2ihAAAAZRFwuOnevbsuu+wyvfDCCxoyZIjCw8OL9GnWrJmGDx9eIQUCAAAEIuBws3v3bjVp0qTUPlFRUVq0aFG5iwIAACivgK+WSk9P19dff12k/euvv9Y333xTIUUBAACUV8DhZty4cdq3b1+R9t9++03jxo2rkKIAAADKK+Bws337dnXp0qVIe+fOnbV9+/YKKQoAAKC8Ag43DodDaWlpRdoPHDigsLCgPmQcAAAg8HBz+eWXa8qUKcrIyPC1HT16VA888IAuu+yyCi0OAAAgUAHvavnXv/6lSy65RE2aNFHnzp0lScnJyUpISNBrr71W4QUCAAAEIuBw07BhQ3333Xd644039O233yoiIkKjR4/WiBEjir3nDQAAQFUq10kyUVFRuu222yq6FgAAgLNW7jOAt2/frr1798rlcvm1/9///d9ZFwUAAFBe5bpD8dChQ7Vt2zZZLBadfKj4ySeAezyeiq0QAAAgAAFfLTVhwgQ1a9ZM6enpioyM1A8//KDPP/9c3bp107p16yqhRAAAgLILeM/Nhg0btHbtWsXFxclqtcpqtapPnz6aOXOm7r77bm3durUy6gQAACiTgPfceDwe1axZU5IUFxen33//XZLUpEkT7dy5s2KrAwAACFDAe24uvPBCffvtt2rWrJl69uypp556Sna7XS+99JKaN29eGTUCAACUWcDhZurUqcrJyZEkPfroo7rqqqv0pz/9SXXq1NHSpUsrvEAAAIBAWIyTlzudhcOHDys2NtZ3xVR1lpmZqZiYGGVkZCg6OjrY5QAAgDIIZPsd0Dk3brdbYWFh+v777/3aa9euHRLBBgAAmF9A4SY8PFznnXce97IBAADVVsBXSz344IN64IEHdPjw4cqoBwAA4KwEfELx3Llz9dNPP6lBgwZq0qSJoqKi/OZv2bKlwooDAAAIVMDhZsiQIZVQBgAAQMWokKulQglXSwEAEHoq7WopAACA6i7gw1JWq7XUy765kgoAAARTwOFm2bJlfu/dbre2bt2qV155RY888kiFFQYAAFAeFXbOzZtvvqmlS5fqgw8+qIiPqzSccwMAQOgJyjk3F110kZKSkirq4wAAAMqlQsLNsWPH9O9//1sNGzasiI8DAAAot4DPuSn8gEzDMJSVlaXIyEi9/vrrFVocAABAoAION88884xfuLFarapbt6569uyp2NjYCi0OAAAgUAGHm5tvvrkSygAAAKgYAZ9zs2jRIr3zzjtF2t955x298sorFVIUAABAeQUcbmbOnKm4uLgi7fHx8ZoxY0aFFAUAAFBeAYebvXv3qlmzZkXamzRpor1791ZIUQAAAOUVcLiJj4/Xd999V6T922+/VZ06dSqkKAAAgPIKONyMGDFCd999tz799FN5PB55PB6tXbtWEyZM0PDhwyujRgAAgDIL+Gqpxx57TL/++qsGDBigsLCCxb1er2666SbOuQEAAEFX7mdL7dq1S8nJyYqIiFD79u3VpEmTiq6tUvBsKQAAQk8g2++A99yc1KpVK7Vq1aq8iwMAAFSKgM+5ufbaa/Xkk08WaX/qqad03XXXVUhRAAAA5RVwuPn88881aNCgIu1XXHGFPv/88wopCgAAoLwCDjfZ2dmy2+1F2sPDw5WZmVkhRQEAAJRXwOGmffv2Wrp0aZH2JUuWqF27dhVSFAAAQHkFfELxQw89pGuuuUY///yz+vfvL0lKSkrSm2++qXfffbfCCwQAAAhEwOFm8ODBWr58uWbMmKF3331XERER6tixo9auXavatWtXRo0AAABlVu773JyUmZmpt956SwsWLNDmzZvl8XgqqrZKwX1uAAAIPYFsvwM+5+akzz//XKNGjVKDBg00a9Ys9e/fX1999VV5Pw4AAKBCBHRYKjU1VYsXL9aCBQuUmZmp66+/Xnl5eVq+fDknEwMAgGqhzHtuBg8erNatW+u7777TnDlz9Pvvv+u5556rzNoAAAACVuY9Nx999JHuvvtu3XHHHTx2AQAAVFtl3nPzxRdfKCsrS127dlXPnj01d+5cHTp0qDJrAwAACFiZw81FF12kl19+WQcOHNDtt9+uJUuWqEGDBvJ6vVq9erWysrIqs04AAIAyOatLwXfu3KkFCxbotdde09GjR3XZZZdpxYoVFVlfheNScAAAQk+VXAouSa1bt9ZTTz2l/fv366233jqbjwIAAKgQZxVuTrLZbBoyZEi599rMmzdPTZs2ldPpVM+ePbVx48YS+/br108Wi6XIdOWVV5a3fAAAYCIVEm7OxtKlSzVp0iRNnz5dW7ZsUceOHTVw4EClp6cX2//999/XgQMHfNP3338vm82m6667roorBwAA1VHQw83s2bN16623avTo0WrXrp3mz5+vyMhILVy4sNj+tWvXVr169XzT6tWrFRkZSbgBAACSghxuXC6XNm/erMTERF+b1WpVYmKiNmzYUKbPWLBggYYPH66oqKhi5+fl5SkzM9NvAgAA5hXUcHPo0CF5PB4lJCT4tSckJCg1NfWMy2/cuFHff/+9xowZU2KfmTNnKiYmxjc1btz4rOsGAADVV9APS52NBQsWqH379urRo0eJfaZMmaKMjAzftG/fviqsEAAAVLWAHpxZ0eLi4mSz2ZSWlubXnpaWpnr16pW6bE5OjpYsWaJHH3201H4Oh0MOh+OsawUAAKEhqHtu7Ha7unbtqqSkJF+b1+tVUlKSevXqVeqy77zzjvLy8vTXv/61sssEAAAhJKh7biRp0qRJGjVqlLp166YePXpozpw5ysnJ0ejRoyVJN910kxo2bKiZM2f6LbdgwQINGTJEderUCUbZAACgmgp6uBk2bJgOHjyoadOmKTU1VZ06ddKqVat8Jxnv3btXVqv/DqadO3fqiy++0CeffBKMkgEAQDV2Vs+WCkU8WwoAgNBTZc+WAgAAqG4INwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFSCHm7mzZunpk2byul0qmfPntq4cWOp/Y8ePapx48apfv36cjgcOv/88/Xhhx9WUbUAAKC6Cwvmly9dulSTJk3S/Pnz1bNnT82ZM0cDBw7Uzp07FR8fX6S/y+XSZZddpvj4eL377rtq2LCh9uzZo1q1alV98QAAoFqyGIZhBOvLe/bsqe7du2vu3LmSJK/Xq8aNG+uuu+7S5MmTi/SfP3++nn76ae3YsUPh4eHl+s7MzEzFxMQoIyND0dHRZ1U/AACoGoFsv4N2WMrlcmnz5s1KTEw8VYzVqsTERG3YsKHYZVasWKFevXpp3LhxSkhI0IUXXqgZM2bI4/GU+D15eXnKzMz0mwAAgHkFLdwcOnRIHo9HCQkJfu0JCQlKTU0tdpndu3fr3Xfflcfj0YcffqiHHnpIs2bN0j//+c8Sv2fmzJmKiYnxTY0bN67QcQAAgOol6CcUB8Lr9So+Pl4vvfSSunbtqmHDhunBBx/U/PnzS1xmypQpysjI8E379u2rwooBAEBVC9oJxXFxcbLZbEpLS/NrT0tLU7169Ypdpn79+goPD5fNZvO1tW3bVqmpqXK5XLLb7UWWcTgccjgcFVs8AACotoK258Zut6tr165KSkrytXm9XiUlJalXr17FLnPxxRfrp59+ktfr9bX9+OOPql+/frHBBgAAnHuCelhq0qRJevnll/XKK68oJSVFd9xxh3JycjR69GhJ0k033aQpU6b4+t9xxx06fPiwJkyYoB9//FErV67UjBkzNG7cuGANAQAAVDNBvc/NsGHDdPDgQU2bNk2pqanq1KmTVq1a5TvJeO/evbJaT+Wvxo0b6+OPP9Y999yjDh06qGHDhpowYYLuv//+YA0BAABUM0G9z00wcJ8bAABCT0jc5wYAAKAyEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICphAW7AACA+Xk8Hrnd7mCXgWouPDxcNpvtrD+HcAMAqFTZ2dnav3+/DMMIdimo5iwWixo1aqQaNWqc1ecQbgAAlcbj8Wj//v2KjIxU3bp1ZbFYgl0SqinDMHTw4EHt379frVq1Oqs9OIQbAEClcbvdMgxDdevWVURERLDLQTVXt25d/frrr3K73WcVbjihGABQ6dhjg7KoqH8nhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAEIAN0EsO8INAKDKGIahXFd+UKZAbyK4atUq9enTR7Vq1VKdOnV01VVX6eeff/bN379/v0aMGKHatWsrKipK3bp109dff+2b///+3/9T9+7d5XQ6FRcXp6FDh/rmWSwWLV++3O/7atWqpcWLF0uSfv31V1ksFi1dulR9+/aV0+nUG2+8oT/++EMjRoxQw4YNFRkZqfbt2+utt97y+xyv16unnnpKLVu2lMPh0HnnnafHH39cktS/f3+NHz/er//Bgwdlt9uVlJQU0O+nOuM+NwCAKnPM7VG7aR8H5bu3PzpQkfayb/ZycnI0adIkdejQQdnZ2Zo2bZqGDh2q5ORk5ebmqm/fvmrYsKFWrFihevXqacuWLfJ6vZKklStXaujQoXrwwQf16quvyuVy6cMPPwy45smTJ2vWrFnq3LmznE6njh8/rq5du+r+++9XdHS0Vq5cqRtvvFEtWrRQjx49JElTpkzRyy+/rGeeeUZ9+vTRgQMHtGPHDknSmDFjNH78eM2aNUsOh0OS9Prrr6thw4bq379/wPVVV4QbAACKce211/q9X7hwoerWravt27fryy+/1MGDB7Vp0ybVrl1bktSyZUtf38cff1zDhw/XI4884mvr2LFjwDVMnDhR11xzjV/bvffe63t911136eOPP9bbb7+tHj16KCsrS88++6zmzp2rUaNGSZJatGihPn36SJKuueYajR8/Xh988IGuv/56SdLixYt18803m+peRIQbAECViQi3afujA4P23YHYtWuXpk2bpq+//lqHDh3y7ZXZu3evkpOT1blzZ1+wKSw5OVm33nrrWdfcrVs3v/cej0czZszQ22+/rd9++00ul0t5eXmKjIyUJKWkpCgvL08DBgwo9vOcTqduvPFGLVy4UNdff722bNmi77//XitWrDjrWqsTwg0AoMpYLJaADg0F0+DBg9WkSRO9/PLLatCggbxery688EK5XK4zPkriTPMtFkuRc4CKO2E4KirK7/3TTz+tZ599VnPmzFH79u0VFRWliRMnyuVylel7pYJDU506ddL+/fu1aNEi9e/fX02aNDnjcqGEE4oBACjkjz/+0M6dOzV16lQNGDBAbdu21ZEjR3zzO3TooOTkZB0+fLjY5Tt06FDqCbp169bVgQMHfO937dql3NzcM9a1fv16XX311frrX/+qjh07qnnz5vrxxx9981u1aqWIiIhSv7t9+/bq1q2bXn75Zb355pu65ZZbzvi9oYZwAwBAIbGxsapTp45eeukl/fTTT1q7dq0mTZrkmz9ixAjVq1dPQ4YM0fr167V7926999572rBhgyRp+vTpeuuttzR9+nSlpKRo27ZtevLJJ33L9+/fX3PnztXWrVv1zTffaOzYsQoPDz9jXa1atdLq1av15ZdfKiUlRbfffrvS0tJ8851Op+6//37dd999evXVV/Xzzz/rq6++0oIFC/w+Z8yYMXriiSdkGIbfVVxmQbgBAKAQq9WqJUuWaPPmzbrwwgt1zz336Omnn/bNt9vt+uSTTxQfH69Bgwapffv2euKJJ3xPsu7Xr5/eeecdrVixQp06dVL//v21ceNG3/KzZs1S48aN9ac//Uk33HCD7r33Xt95M6WZOnWqunTpooEDB6pfv36+gHW6hx56SH//+981bdo0tW3bVsOGDVN6erpfnxEjRigsLEwjRoyQ0+k8i99U9WQxAr3wP8RlZmYqJiZGGRkZio6ODnY5AGBqx48f1y+//KJmzZqZciMaqn799Ve1aNFCmzZtUpcuXYJdjk9p/14C2X6HxlldAADgrLndbv3xxx+aOnWqLrroomoVbCoSh6UAADhHrF+/XvXr19emTZs0f/78YJdTadhzAwDAOaJfv34BP4YiFLHnBgAAmArhBgAAmArhBgAAmArhBgAAmArhBgAAmArhBgAAmArhBgCAStC0aVPNmTMn2GWckwg3AADAVAg3AADAj8fjkdfrDXYZ5Ua4AQBUHcOQXDnBmQK4M+9LL72kBg0aFNnAX3311brlllv0888/6+qrr1ZCQoJq1Kih7t27a82aNeX+tcyePVvt27dXVFSUGjdurDvvvFPZ2dl+fdavX69+/fopMjJSsbGxGjhwoI4cOSJJ8nq9euqpp9SyZUs5HA6dd955evzxxyVJ69atk8Vi0dGjR32flZycLIvFol9//VWStHjxYtWqVUsrVqxQu3bt5HA4tHfvXm3atEmXXXaZ4uLiFBMTo759+2rLli1+dR09elS33367EhIS5HQ6deGFF+q///2vcnJyFB0drXfffdev//LlyxUVFaWsrKxy/77OhMcvAACqjjtXmtEgON/9wO+SPapMXa+77jrddddd+vTTTzVgwABJ0uHDh7Vq1Sp9+OGHys7O1qBBg/T444/L4XDo1Vdf1eDBg7Vz506dd955AZdmtVr173//W82aNdPu3bt155136r777tPzzz8vqSCMDBgwQLfccoueffZZhYWF6dNPP5XH45EkTZkyRS+//LKeeeYZ9enTRwcOHNCOHTsCqiE3N1dPPvmk/vOf/6hOnTqKj4/X7t27NWrUKD333HMyDEOzZs3SoEGDtGvXLtWsWVNer1dXXHGFsrKy9Prrr6tFixbavn27bDaboqKiNHz4cC1atEh/+ctffN9z8n3NmjUD/j2VFeEGAIBCYmNjdcUVV+jNN9/0hZt3331XcXFxuvTSS2W1WtWxY0df/8cee0zLli3TihUrNH78+IC/b+LEib7XTZs21T//+U+NHTvWF26eeuopdevWzfdeki644AJJUlZWlp599lnNnTtXo0aNkiS1aNFCffr0CagGt9ut559/3m9c/fv39+vz0ksvqVatWvrss8901VVXac2aNdq4caNSUlJ0/vnnS5KaN2/u6z9mzBj17t1bBw4cUP369ZWenq4PP/zwrPZylQXhBgBQdcIjC/agBOu7AzBy5Ejdeuutev755+VwOPTGG29o+PDhslqtys7O1sMPP6yVK1fqwIEDys/P17Fjx7R3795ylbZmzRrNnDlTO3bsUGZmpvLz83X8+HHl5uYqMjJSycnJuu6664pdNiUlRXl5eb4QVl52u10dOnTwa0tLS9PUqVO1bt06paeny+PxKDc31zfO5ORkNWrUyBdsCuvRo4cuuOACvfLKK5o8ebJef/11NWnSRJdccslZ1XomnHMDAKg6FkvBoaFgTBZLQKUOHjxYhmFo5cqV2rdvn/73v/9p5MiRkqR7771Xy5Yt04wZM/S///1PycnJat++vVwuV8C/kl9//VVXXXWVOnTooPfee0+bN2/WvHnzJMn3eRERESUuX9o8qeCQlyS/p4G73e5iP8dS6Hc0atQoJScn69lnn9WXX36p5ORk1alTp0x1nTRmzBgtXrxYUsEhqdGjRxf5nopGuAEAoBhOp1PXXHON3njjDb311ltq3bq1unTpIqng5N6bb75ZQ4cOVfv27VWvXj3fybmB2rx5s7xer2bNmqWLLrpI559/vn7/3X/vVocOHZSUlFTs8q1atVJERESJ8+vWrStJOnDggK8tOTm5TLWtX79ed999twYNGqQLLrhADodDhw4d8qtr//79+vHHH0v8jL/+9a/as2eP/v3vf2v79u2+Q2eViXADAEAJRo4cqZUrV2rhwoW+vTZSQaB4//33lZycrG+//VY33HBDuS+dbtmypdxut5577jnt3r1br732mubPn+/XZ8qUKdq0aZPuvPNOfffdd9qxY4deeOEFHTp0SE6nU/fff7/uu+8+vfrqq/r555/11VdfacGCBb7Pb9y4sR5++GHt2rVLK1eu1KxZs8pUW6tWrfTaa68pJSVFX3/9tUaOHOm3t6Zv37665JJLdO2112r16tX65Zdf9NFHH2nVqlW+PrGxsbrmmmv0j3/8Q5dffrkaNWpUrt9TIAg3AACUoH///qpdu7Z27typG264wdc+e/ZsxcbGqnfv3ho8eLAGDhzo26sTqI4dO2r27Nl68skndeGFF+qNN97QzJkz/fqcf/75+uSTT/Ttt9+qR48e6tWrlz744AOFhRWcOvvQQw/p73//u6ZNm6a2bdtq2LBhSk9PlySFh4frrbfe0o4dO9ShQwc9+eST+uc//1mm2hYsWKAjR46oS5cuuvHGG3X33XcrPj7er897772n7t27a8SIEWrXrp3uu+8+31VcJ/3tb3+Ty+XSLbfcUq7fUaAshhHAhf8mkJmZqZiYGGVkZCg6OjrY5QCAqR0/fly//PKLmjVrJqfTGexyECSvvfaa7rnnHv3++++y2+0l9ivt30sg22+ulgIAAJUiNzdXBw4c0BNPPKHbb7+91GBTkTgsBQBAJXrjjTdUo0aNYqeT96oxq6eeekpt2rRRvXr1NGXKlCr7Xg5LAQAqDYelCm6yl5aWVuy88PBwNWnSpIorqr44LAUAQAioWbNmpT5qAEVxWAoAUOnOsYMEKKeK+ndCuAEAVBqbzSZJ5bpzL849J/+dnPx3U14clgIAVJqwsDBFRkbq4MGDCg8P9z0KACjM6/Xq4MGDioyM9N2/p7wINwCASmOxWFS/fn398ssv2rNnT7DLQTVntVp13nnnnfWzpwg3AIBKZbfb1apVKw5N4YzsdnuF7N0j3AAAKp3Vaj1nLwVH1asWBz/nzZunpk2byul0qmfPntq4cWOJfRcvXiyLxeI38QcDAABOCnq4Wbp0qSZNmqTp06dry5Yt6tixowYOHOh74FdxoqOjdeDAAd/EcVwAAHBS0MPN7Nmzdeutt2r06NFq166d5s+fr8jISC1cuLDEZSwWi+rVq+ebEhISqrBiAABQnQX1nBuXy6XNmzf7PW/CarUqMTFRGzZsKHG57OxsNWnSRF6vV126dNGMGTNKfD5HXl6e8vLyfO8zMjIkFdzGGQAAhIaT2+2y3OgvqOHm0KFD8ng8Rfa8JCQkaMeOHcUu07p1ay1cuFAdOnRQRkaG/vWvf6l379764Ycf1KhRoyL9Z86cqUceeaRIe+PGjStmEAAAoMpkZWUpJiam1D4hd7VUr1691KtXL9/73r17q23btnrxxRf12GOPFek/ZcoUTZo0yffe6/Xq8OHDqlOnzllfR19YZmamGjdurH379pnyoZxmH59k/jEyvtBn9jEyvtBXWWM0DENZWVlq0KDBGfsGNdzExcXJZrMVeVpqWlqa6tWrV6bPCA8PV+fOnfXTTz8VO9/hcMjhcPi11apVq1z1llV0dLRp/9FK5h+fZP4xMr7QZ/YxMr7QVxljPNMem5OCekKx3W5X165dlZSU5Gvzer1KSkry2ztTGo/Ho23btql+/fqVVSYAAAghQT8sNWnSJI0aNUrdunVTjx49NGfOHOXk5Gj06NGSpJtuukkNGzbUzJkzJUmPPvqoLrroIrVs2VJHjx7V008/rT179mjMmDHBHAYAAKgmgh5uhg0bpoMHD2ratGlKTU1Vp06dtGrVKt9Jxnv37vW7FfORI0d06623KjU1VbGxseratau+/PJLtWvXLlhD8HE4HJo+fXqRw2BmYfbxSeYfI+MLfWYfI+MLfdVhjBajLNdUAQAAhIig38QPAACgIhFuAACAqRBuAACAqRBuAACAqRBuAjRv3jw1bdpUTqdTPXv21MaNG0vt/84776hNmzZyOp1q3769PvzwwyqqtHwCGd/ixYtlsVj8JqfTWYXVBubzzz/X4MGD1aBBA1ksFi1fvvyMy6xbt05dunSRw+FQy5YttXjx4kqvs7wCHd+6deuKrD+LxaLU1NSqKThAM2fOVPfu3VWzZk3Fx8dryJAh2rlz5xmXC6W/wfKMMZT+Dl944QV16NDBd3O3Xr166aOPPip1mVBaf4GOL5TWXXGeeOIJWSwWTZw4sdR+wViHhJsALF26VJMmTdL06dO1ZcsWdezYUQMHDlR6enqx/b/88kuNGDFCf/vb37R161YNGTJEQ4YM0ffff1/FlZdNoOOTCu5AeeDAAd+0Z8+eKqw4MDk5OerYsaPmzZtXpv6//PKLrrzySl166aVKTk7WxIkTNWbMGH388ceVXGn5BDq+k3bu3Om3DuPj4yupwrPz2Wefady4cfrqq6+0evVqud1uXX755crJySlxmVD7GyzPGKXQ+Tts1KiRnnjiCW3evFnffPON+vfvr6uvvlo//PBDsf1Dbf0FOj4pdNZdYZs2bdKLL76oDh06lNovaOvQQJn16NHDGDdunO+9x+MxGjRoYMycObPY/tdff71x5ZVX+rX17NnTuP322yu1zvIKdHyLFi0yYmJiqqi6iiXJWLZsWal97rvvPuOCCy7waxs2bJgxcODASqysYpRlfJ9++qkhyThy5EiV1FTR0tPTDUnGZ599VmKfUPsbLKwsYwzlv0PDMIzY2FjjP//5T7HzQn39GUbp4wvVdZeVlWW0atXKWL16tdG3b19jwoQJJfYN1jpkz00ZuVwubd68WYmJib42q9WqxMREbdiwodhlNmzY4NdfkgYOHFhi/2Aqz/gkKTs7W02aNFHjxo3P+H8ooSaU1t/Z6NSpk+rXr6/LLrtM69evD3Y5ZZaRkSFJql27dol9Qn0dlmWMUmj+HXo8Hi1ZskQ5OTklPm4nlNdfWcYnhea6GzdunK688soi66Y4wVqHhJsyOnTokDwej+/OySclJCSUeI5CampqQP2DqTzja926tRYuXKgPPvhAr7/+urxer3r37q39+/dXRcmVrqT1l5mZqWPHjgWpqopTv359zZ8/X++9957ee+89NW7cWP369dOWLVuCXdoZeb1eTZw4URdffLEuvPDCEvuF0t9gYWUdY6j9HW7btk01atSQw+HQ2LFjtWzZshLvMB+K6y+Q8YXaupOkJUuWaMuWLb5HIp1JsNZh0B+/gNDVq1cvv/8j6d27t9q2basXX3xRjz32WBArQ1m0bt1arVu39r3v3bu3fv75Zz3zzDN67bXXgljZmY0bN07ff/+9vvjii2CXUmnKOsZQ+zts3bq1kpOTlZGRoXfffVejRo3SZ599Vi0eoVMRAhlfqK27ffv2acKECVq9enW1P/GZcFNGcXFxstlsSktL82tPS0tTvXr1il2mXr16AfUPpvKMr7Dw8HB17txZP/30U2WUWOVKWn/R0dGKiIgIUlWVq0ePHtU+MIwfP17//e9/9fnnn6tRo0al9g2lv8HTBTLGwqr736HdblfLli0lSV27dtWmTZv07LPP6sUXXyzSNxTXXyDjK6y6r7vNmzcrPT1dXbp08bV5PB59/vnnmjt3rvLy8mSz2fyWCdY65LBUGdntdnXt2lVJSUm+Nq/Xq6SkpBKPp/bq1cuvvyStXr261OOvwVKe8RXm8Xi0bds21a9fv7LKrFKhtP4qSnJycrVdf4ZhaPz48Vq2bJnWrl2rZs2anXGZUFuH5RljYaH2d+j1epWXl1fsvFBbf8UpbXyFVfd1N2DAAG3btk3Jycm+qVu3bho5cqSSk5OLBBspiOuwUk9XNpklS5YYDofDWLx4sbF9+3bjtttuM2rVqmWkpqYahmEYN954ozF58mRf//Xr1xthYWHGv/71LyMlJcWYPn26ER4ebmzbti1YQyhVoON75JFHjI8//tj4+eefjc2bNxvDhw83nE6n8cMPPwRrCKXKysoytm7damzdutWQZMyePdvYunWrsWfPHsMwDGPy5MnGjTfe6Ou/e/duIzIy0vjHP/5hpKSkGPPmzTNsNpuxatWqYA2hVIGO75lnnjGWL19u7Nq1y9i2bZsxYcIEw2q1GmvWrAnWEEp1xx13GDExMca6deuMAwcO+Kbc3Fxfn1D/GyzPGEPp73Dy5MnGZ599Zvzyyy/Gd999Z0yePNmwWCzGJ598YhhG6K+/QMcXSuuuJIWvlqou65BwE6DnnnvOOO+88wy73W706NHD+Oqrr3zz+vbta4waNcqv/9tvv22cf/75ht1uNy644AJj5cqVVVxxYAIZ38SJE319ExISjEGDBhlbtmwJQtVlc/LS58LTyTGNGjXK6Nu3b5FlOnXqZNjtdqN58+bGokWLqrzusgp0fE8++aTRokULw+l0GrVr1zb69etnrF27NjjFl0FxY5Pkt05C/W+wPGMMpb/DW265xWjSpIlht9uNunXrGgMGDPBt+A0j9NdfoOMLpXVXksLhprqsQ4thGEbl7hsCAACoOpxzAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwA+CcZ7FYtHz58mCXAaCCEG4ABNXNN98si8VSZPrzn/8c7NIAhCieCg4g6P785z9r0aJFfm0OhyNI1QAIdey5ARB0DodD9erV85tiY2MlFRwyeuGFF3TFFVcoIiJCzZs317vvvuu3/LZt29S/f39FRESoTp06uu2225Sdne3XZ+HChbrgggvkcDhUv359jR8/3m/+oUOHNHToUEVGRqpVq1ZasWJF5Q4aQKUh3ACo9h566CFde+21+vbbbzVy5EgNHz5cKSkpkqScnBwNHDhQsbGx2rRpk9555x2tWbPGL7y88MILGjdunG677TZt27ZNK1asUMuWLf2+45FHHtH111+v7777ToMGDdLIkSN1+PDhKh0ngApS6Y/mBIBSjBo1yrDZbEZUVJTf9PjjjxuGUfCk7LFjx/ot07NnT+OOO+4wDMMwXnrpJSM2NtbIzs72zV+5cqVhtVqN1NRUwzAMo0GDBsaDDz5YYg2SjKlTp/reZ2dnG5KMjz76qMLGCaDqcM4NgKC79NJL9cILL/i11a5d2/e6V69efvN69eql5ORkSVJKSoo6duyoqKgo3/yLL75YXq9XO3fulMVi0e+//64BAwaUWkOHDh18r6OiohQdHa309PTyDglAEBFuAARdVFRUkcNEFSUiIqJM/cLDw/3eWywWeb3eyigJQCXjnBsA1d5XX31V5H3btm0lSW3bttW3336rnJwc3/z169fLarWqdevWqlmzppo2baqkpKQqrRlA8LDnBkDQ5eXlKTU11a8tLCxMcXFxkqR33nlH3bp1U58+ffTGG29o48aNWrBggSRp5MiRmj59ukaNGqWHH35YBw8e1F133aUbb7xRCQkJkqSHH35YY8eOVXx8vK644gplZWVp/fr1uuuuu6p2oACqBOEGQNCtWrVK9evX92tr3bq1duzYIangSqYlS5bozjvvVP369fXWW2+pXbt2kqTIyEh9/PHHmjBhgrp3767IyEhde+21mj17tu+zRo0apePHj+uZZ57Rvffeq7i4OP3lL3+pugECqFIWwzCMYBcBACWxWCxatmyZhgwZEuxSAIQIzrkBAACmQrgBAACmwjk3AKo1jpwDCBR7bgAAgKkQbgAAgKkQbgAAgKkQbgAAgKkQbgAAgKkQbgAAgKkQbgAAgKkQbgAAgKkQbgAAgKn8f4/J8IvjorejAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b906a155"
      },
      "source": [
        "### 5 How do you install PyTorch and verify the PyTorch installation?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eceb71bd",
        "outputId": "a2bc4a01-bf38-43d3-b141-8266cfda7f12"
      },
      "source": [
        "# Install PyTorch (you might need to specify CUDA version)\n",
        "!pip install torch torchvision torchaudio\n",
        "\n",
        "# Verify installation\n",
        "import torch\n",
        "print(torch.__version__)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "2.6.0+cu124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49f846b2"
      },
      "source": [
        "### 6 How do you create a simple neural network in PyTorch?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cf9caa69",
        "outputId": "ca1fb4f3-784d-4a8f-9680-2eaa4883b0f2"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(784, 128)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model = SimpleNN()\n",
        "print(model)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SimpleNN(\n",
            "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6f9723cf"
      },
      "source": [
        "### 7 **How** do you define a loss function and optimizer in PyTorch?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e29e083f",
        "outputId": "9faea88d-7cef-4b58-b144-042db33dc5f6"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Assuming you have a model defined as 'model'\n",
        "# model = SimpleNN()\n",
        "\n",
        "# Define a loss function (e.g., Cross-Entropy Loss for classification)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Define an optimizer (e.g., Adam)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "print(\"Loss Function:\", criterion)\n",
        "print(\"Optimizer:\", optimizer)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss Function: CrossEntropyLoss()\n",
            "Optimizer: Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    capturable: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.001\n",
            "    maximize: False\n",
            "    weight_decay: 0\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7e6875a"
      },
      "source": [
        "### 8 How do you implement a custom loss function in PyTorch?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61d4e825"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "def custom_mse_loss(output, target):\n",
        "  \"\"\"Custom Mean Squared Error loss function.\"\"\"\n",
        "  return torch.mean((output - target)**2)\n",
        "\n",
        "# Example usage (assuming you have output and target tensors)\n",
        "# output = torch.randn(10, 1)\n",
        "# target = torch.randn(10, 1)\n",
        "# loss = custom_mse_loss(output, target)\n",
        "# print(loss)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02397dc2"
      },
      "source": [
        "### 9 How do you save and load a TensorFlow model?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fd1e7de",
        "outputId": "eac3006e-b0ef-4b49-b810-fbf04d39e039"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import os\n",
        "\n",
        "# Create a simple model\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(64, activation='relu', input_shape=(784,)),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Save the model\n",
        "model.save(\"my_model.h5\")\n",
        "\n",
        "# Load the model\n",
        "loaded_model = keras.models.load_model(\"my_model.h5\")\n",
        "\n",
        "print(\"Model saved and loaded successfully!\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved and loaded successfully!\n"
          ]
        }
      ]
    }
  ]
}